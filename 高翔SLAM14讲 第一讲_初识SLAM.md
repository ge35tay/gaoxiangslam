# 高翔SLAM14讲 第一讲

SLAM: Simultaneous Localization and Mapping. 指搭载特定传感器的主体， 在没有环境先验信息的情况下于运动过程中建立环境的模型，同时估计自己的运动。 若传感器为相机 则为视觉Slam

## 1.1 前言

SLAM的目的是解决 **定位与地图构建** 两个问题, 一边要估计传感器自身的位置，一边要建立周围环境的模型， 这需要运用到传感器的信息。  当相机作为传感器时， 需要根据一张张连续运动的图像，从中推断相机的运动以及周围环境的情况

## 1.2 初识SLAM

两类传感器: 1. 携带于机器人本体上的，例如机器人的相机 测量一些间接的物理量而不是直接的位置数据，从这些间接的数据来推算自己的位置; 2. 安装于环境中的， 安装于环境中的传感设备通常能够直接测量到机器人的位置信息，简单有效地解决定位问题， 但这也限制了机器人的使用范围， 只有当传感器被安装时才能定位， 因此他虽然简单可靠但是无法提供普遍通用的解决方案。

### 1.2.1 用于SLAM的各种相机

- 单目相机

  只用一个摄像头进行SLAM，单目相机结构简单，成本低。

  照片本质上是拍照的场景在相机成像平面上留下的一个投影， 他以二维的形式反应三维的世界，在这个过程中距离信息被忽略。

  > 因此除非转动视角，观察场景的三维结构否则无法获得场景的距离信息。 对于单目SLAM， 我们必须移动相机才能估计他的运动，同时估计场景中物体的 **远近和大小** . (结构)   

  我们可以从图像中物体的运动方向以及物体在图像中的运动快慢， 形成视差， 可以定量的判断物体的远近

​		但是只知道物体的远近，如何确定物体的真实尺度？

​		直观上，把场景的大小和相机的运动同时放大两倍，单目相机所观察到的景象是一样的，这说明单目相机SLAM的轨迹和地图，与真实的轨迹地图相差一个因子， 即所谓的 **尺度**  .  但是单目相机SLAM无法仅凭图像确定该尺度

- 双目相机和深度相机

  双目和深度相机可以通过某种手段测量物体和我们的距离，克服单目无法知道距离的缺点。

  已知距离，我们就可以将场景的三维结构通过单个图像恢复出来，消除尺度的不确定性。

  - 双目相机由两个单目相机组成，且两相机之间的距离 （**基线**）已知，可以通过基线确定每个像素的空间位置. 一般而言基线距离越大，所能测得的距离越远  ===> 软件计算， 计算量大
  - 深度相机 （RGB-D），最大的特点是可以通过红外结构光或Time-of-Flight (TOF) 原理， 像激光传感器那样通过主动向物体发射光并接受返回的光，测得物体与相机的距离 ===> 物理测量，节省计算量。 不过RGB-D 存在 **测量范围窄， 噪声大， 视野小，易受日光干扰， 无法测量投射材质等问题**， 主要运用于室内，不适用于室外





## 1.3 经典视觉SLAM框架

![image-20220426084639863](C:\Users\24527\AppData\Roaming\Typora\typora-user-images\image-20220426084639863.png)

### 1.3.1 SLAM流程

- **传感器数据**: 相机图像信息的读取与预处理

- **视觉里程计 (Visual Odemetry VO)**， 视觉里程计的任务是估算相邻图像间相机的运动以及局部地图的样子， VO又称为**前端**

  - (1) 视觉里程计通过相邻帧间的图像估计相机运动，并恢复场景的空间结构。 由于它只计算相邻时刻的运动，而和再往前的过去的信息没有关联，因此被称为里程计

    联系各个相邻时刻的运动可以得出整个机器人的运动轨迹，解决定位问题。 但是仅通过VO会产生轨迹的累积漂移，一段时间后轨迹估计将不再准确

  - (2) 在视觉Slam中主要涉及图像的特征提取与匹配

- **后端优化(optimization)** 后端接受不同时刻视觉里程计所测量的相机位姿，以及回环检测的信息，对他们进行优化，得到全局一致的轨迹和地图， Optimization又被称为后端。

  - (1) 后端优化主要指处理SLAM过程中的噪声问题。后端要考虑的问题就是如何从这些带有噪声的数据中估计整个系统的状态 （**机器人自身的轨迹与地图**），以及这个状态的估计不确定有多大 （**最大后验概率估计 Maximum-a-Posteriori MAP**）
  - (2) 在视觉Slam中主要涉及滤波与非线性优化算法

- **回环检测(Loop Closing)** 判断机器人是否到达过先前的位置，如果检测到回环则将信息提供给后端处理

  主要解决位置估计随时间漂移的问题。 我们想让机器拥有知道自己到过哪，再将位置估计值拉到该位置，以消除飘移。 例如通过图像间的相似性判断

- **建图** 根据估计的轨迹，建立与任务要求对应的地图。

  地图是对环境的描述。 建图视应用场景而定，没有固定的形式和算法

  - **度量地图(Metric Map)** 度量地图强调精确地表示地图中物体的位置关系， 通常可分为 **稀疏(Sparse)地图** 和 **稠密(Dense)地图**

    - 稀疏地图对场景进行了一定的抽象，不要表达所有的物体， 选择一部分具有代表性的东西做路标即可，用于定位
    - 稠密地图则注重于对所有看到的物体建模， 用于导航

    二维度量地图是许多个小格子，而三维度量地图是许多个小方块。 每个单位具有**占有，空闲，未知**三种状态，以表达该格内是否有物体。 但这样格子化的表达需要记录每一格的状态，耗费大量存储空间

  - **拓扑地图(Topological Map)** 更强调地图元素之间的关系。 拓扑地图是一个Graph由节点和边组成，只考虑节点中的连通性



如果把SLAM的工作环境限定在静态、刚体、光照变化不明显，没有人为干扰的场景，则该SLAM系统已经相当成熟





## 1.4 SLAM的数学表述

1. 相机在某些时刻采集数据，设这些时刻为 $t = 1, ..., K$ 。 在这些时刻用 $x$ 表达机器人自身的位置，各时刻的位置可被标记为$x_1,... x_k$, 这些位置构成了机器人的运动轨迹

2. 设地图由许多个路标组成的，而在每个时刻，传感器会测量到一部分路标点，得到其观测数据。 不妨设路标点一共有$N$个， 用$y_1,...y_N$

3. - 机器人的运动 >>> 考虑从 $k-1$ 时刻到 $k$ 时刻，机器人的位置是如何变化的

    传感器检测的运动可能有加速度，速度或者路程，all in all 我们如此表达
   $$
   x_k = f(x_{k-1}, u_k, w_k)
   $$
   其中 $u_k$ 为运动传感器的输入， $w_k$ 为噪声

   - 机器人的观测 >>> 假设在 $k$ 时刻，于 $x_k$ 处探测到了某一个路标 $y_j$ ,产生了一个观测数据 $z_{k,j}$ 
     $$
     z_{k,j} = h(y_j, x_k, v_{k,j})
     $$
     其中 $v_{k,j}$ 为观测过程中的噪声

   

   

   